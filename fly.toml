# =============================================================================
# Fly.io Configuration - Lead Service (Staging) - PERFORMANCE OPTIMIZED
# =============================================================================
# Deploy: flyctl deploy
# Logs: flyctl logs
# Status: flyctl status
# Stop: flyctl scale count 0
# Start: flyctl scale count 1
# =============================================================================
# Performance Optimizations Applied:
# - 2 vCPUs for better GC performance (one for app, one for GC/libuv)
# - 1GB RAM with V8 flags optimized in Dockerfile
# - Machine always running to eliminate cold starts
# - Increased concurrency limits
# Based on: https://fastify.dev/docs/latest/Guides/Recommendations/
# =============================================================================

app = "zuclubit-lead-service"
primary_region = "dfw"  # Dallas - Low latency for LATAM

[build]
  dockerfile = "services/lead-service/Dockerfile.flyio"
  build-target = "production"

[build.args]
  # Build context is the root of the monorepo

[env]
  NODE_ENV = "staging"
  PORT = "8080"
  HOST = "0.0.0.0"
  LOG_LEVEL = "info"
  # V8 flags are configured in Dockerfile CMD for proper parsing
  # Additional Node.js options can be set here if needed:
  # NODE_OPTIONS = "--max-old-space-size=768"
  # Database y secrets se configuran con: flyctl secrets set KEY=value

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = false     # Keep machine always running for fast response
  auto_start_machines = true     # Auto-start on incoming requests
  min_machines_running = 1       # Always 1 machine running (eliminates cold starts)
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    hard_limit = 500             # Increased for Fastify's high throughput (~50k RPS)
    soft_limit = 400             # Start scaling earlier

# Health check optimized for faster detection
[[http_service.checks]]
  grace_period = "15s"           # Allow time for app startup
  interval = "30s"
  method = "GET"
  path = "/health"
  timeout = "10s"

# VM Configuration - Optimized for Node.js/Fastify
# Based on: https://fastify.dev/docs/latest/Guides/Recommendations/
# "2 vCPU are recommended per app instance - the second vCPU will mostly
# be used by the garbage collector and libuv threadpool"
[[vm]]
  cpu_kind = "shared"
  cpus = 2                       # 2 vCPUs for GC and libuv optimization
  memory_mb = 1024               # 1GB RAM for V8 heap + OS overhead

[metrics]
  port = 9091
  path = "/metrics"
